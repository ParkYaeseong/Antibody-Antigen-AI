{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"T4","mount_file_id":"1WVtr9_e1k2YLKtrk3Ds1D8wDw66LLML-","authorship_tag":"ABX9TyPbJugpMeEWbzeAyOXXqL+m"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"f71e2bcce13641a48f975b1bb2c04f05":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_8b38e72369a74fbe80c8f31ef417c992","IPY_MODEL_a54ba924dad94a6ebd3f790bef8e44d1","IPY_MODEL_1865fbc3507c4cd68e9b601f0aeb4fe0"],"layout":"IPY_MODEL_d1bdf78d96714f2a92a4eccf7992b152"}},"8b38e72369a74fbe80c8f31ef417c992":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_791e25b12a0d42eba11f66bb54c562ab","placeholder":"​","style":"IPY_MODEL_cd2df12d2d884841b814a25804a75813","value":"Loading checkpoint shards: 100%"}},"a54ba924dad94a6ebd3f790bef8e44d1":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_62a0d23dedd74182986577f78725a964","max":2,"min":0,"orientation":"horizontal","style":"IPY_MODEL_701b3720db3d4c5fb88a7c5b481671f1","value":2}},"1865fbc3507c4cd68e9b601f0aeb4fe0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c417519e99764b23970953e97b4a9116","placeholder":"​","style":"IPY_MODEL_4f0b13da19c0427da5c93e4e4b0c252b","value":" 2/2 [00:00&lt;00:00,  1.61it/s]"}},"d1bdf78d96714f2a92a4eccf7992b152":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"791e25b12a0d42eba11f66bb54c562ab":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cd2df12d2d884841b814a25804a75813":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"62a0d23dedd74182986577f78725a964":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"701b3720db3d4c5fb88a7c5b481671f1":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c417519e99764b23970953e97b4a9116":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4f0b13da19c0427da5c93e4e4b0c252b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Q3eJKLoN7NMs","executionInfo":{"status":"ok","timestamp":1745893664263,"user_tz":-540,"elapsed":9176,"user":{"displayName":"구글개정","userId":"15305168374719957285"}},"outputId":"a7da8a45-4545-4c5e-adbf-bdcc89ac8d17","collapsed":true},"outputs":[{"output_type":"stream","name":"stdout","text":["1단계: NumPy < 2 설치 완료.\n","2단계: 주요 라이브러리 설치/업데이트 완료.\n","Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","Google Drive 마운트 성공.\n","기본 디렉토리: /content/drive/MyDrive/Antibody_AI_Data_Stage1_AbNumber\n","특성 저장 디렉토리: /content/drive/MyDrive/Antibody_AI_Data_Stage1_AbNumber/2_feature_engineered\n","분할 데이터 저장 디렉토리: /content/drive/MyDrive/Antibody_AI_Data_Stage1_AbNumber/3_split_data\n"]}],"source":["# --- 라이브러리 설치 ---\n","# 필수 라이브러리 설치\n","# pip가 Colab 환경에 맞는 호환 버전을 찾도록 함\n","# --- 라이브러리 설치 (2단계) ---\n","\n","# 1단계: NumPy 버전 고정 (< 2)\n","!pip install \"numpy<2\" -q\n","print(\"1단계: NumPy < 2 설치 완료.\")\n","\n","# 2단계: 나머지 라이브러리 설치 (torch, torchvision, torchaudio 포함)\n","# pip가 NumPy 1.x 환경에 맞는 호환 버전을 찾도록 함\n","!pip install transformers torch torchvision torchaudio pandas biopython scikit-learn pyarrow -q --upgrade\n","print(\"2단계: 주요 라이브러리 설치/업데이트 완료.\")\n","\n","# --- Google Drive 마운트 ---\n","from google.colab import drive\n","import os\n","\n","try:\n","    drive.mount('/content/drive')\n","    print(\"Google Drive 마운트 성공.\")\n","except Exception as e:\n","    print(f\"Google Drive 마운트 중 오류 발생: {e}\")\n","    # 필요시 오류 처리\n","\n","# --- 기본 경로 설정 (Colab 환경) ---\n","# Google Drive 내 작업 디렉토리 경로 (본인 환경에 맞게 수정)\n","base_dir = '/content/drive/MyDrive/Antibody_AI_Data_Stage1_AbNumber'\n","if not os.path.exists(base_dir):\n","    print(f\"경고: 기본 디렉토리를 찾을 수 없습니다: {base_dir}\")\n","    print(\"Google Drive 경로를 확인하거나 디렉토리를 생성해주세요.\")\n","    # os.makedirs(base_dir) # 필요시 디렉토리 생성\n","\n","# 중간 결과 저장 경로 설정\n","feature_dir = os.path.join(base_dir, '2_feature_engineered')\n","split_dir = os.path.join(base_dir, '3_split_data')\n","os.makedirs(feature_dir, exist_ok=True)\n","os.makedirs(split_dir, exist_ok=True)\n","\n","print(f\"기본 디렉토리: {base_dir}\")\n","print(f\"특성 저장 디렉토리: {feature_dir}\")\n","print(f\"분할 데이터 저장 디렉토리: {split_dir}\")"]},{"cell_type":"code","source":["# 임포트 테스트 셀 : 위 실행후 런타임 재시작 해야\n","try:\n","    import pandas as pd\n","    import numpy as np\n","    from Bio import SeqIO\n","    from Bio.Seq import Seq\n","    from Bio.SeqRecord import SeqRecord\n","    from sklearn.model_selection import GroupShuffleSplit\n","    from transformers import AutoTokenizer, AutoModel\n","    import torch\n","    import os\n","    import re\n","    import time\n","    print(\"--- 필수 라이브러리 임포트 성공 ---\")\n","    print(f\"NumPy version: {np.__version__}\")\n","    print(f\"Pandas version: {pd.__version__}\")\n","    # 필요시 다른 라이브러리 버전도 확인\n","    # import transformers\n","    # print(f\"Transformers version: {transformers.__version__}\")\n","    # import sklearn\n","    # print(f\"Scikit-learn version: {sklearn.__version__}\")\n","except Exception as e:\n","    print(f\"오류: 라이브러리 임포트 중 문제 발생: {e}\")\n","    # 오류 발생 시 여기서 멈추고 원인 파악"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Fc1KT5WyWV4M","executionInfo":{"status":"ok","timestamp":1745893669037,"user_tz":-540,"elapsed":4770,"user":{"displayName":"구글개정","userId":"15305168374719957285"}},"outputId":"d59d309e-4240-43c8-f8f4-ce1555920c92"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["--- 필수 라이브러리 임포트 성공 ---\n","NumPy version: 1.26.4\n","Pandas version: 2.2.3\n"]}]},{"cell_type":"code","source":["import os\n","import time\n","import re # 클러스터 파일 파싱용\n","import pandas as pd\n","import numpy as np\n","from Bio import SeqIO\n","from Bio.Seq import Seq\n","from Bio.SeqRecord import SeqRecord\n","from sklearn.model_selection import GroupShuffleSplit\n","from transformers import AutoTokenizer, AutoModel\n","import torch\n","\n","# --- GPU 상태 확인 ---\n","if torch.cuda.is_available():\n","    device = torch.device(\"cuda\")\n","    print(f'GPU 사용 가능: {torch.cuda.get_device_name(0)}')\n","    # 사용 가능한 총 메모리와 현재 할당된 메모리 확인 (Bytes 단위)\n","    total_mem = torch.cuda.get_device_properties(0).total_memory\n","    free_mem = total_mem - torch.cuda.memory_allocated(0)\n","    print(f'GPU 총 메모리: {total_mem / (1024**3):.2f} GB')\n","    print(f'GPU 사용 가능 메모리 (추정): {free_mem / (1024**3):.2f} GB')\n","    # 3B 모델은 최소 12-16GB 이상의 VRAM 권장\n","    if free_mem / (1024**3) < 12:\n","         print(\"경고: 사용 가능한 GPU 메모리가 12GB 미만입니다. 3B 모델 실행 시 메모리 부족 오류가 발생할 수 있습니다.\")\n","         print(\"모델 크기를 줄이거나 배치 크기를 매우 작게 조절해야 할 수 있습니다.\")\n","else:\n","    device = torch.device(\"cpu\")\n","    print('GPU 사용 불가, CPU 사용.')\n","    print(\"경고: CPU 사용 시 임베딩 생성 속도가 매우 느립니다.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Y0Podw178-Xe","executionInfo":{"status":"ok","timestamp":1745893669045,"user_tz":-540,"elapsed":6,"user":{"displayName":"구글개정","userId":"15305168374719957285"}},"outputId":"279d3b3f-e6bd-441a-8379-e14cd02f52ca"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["GPU 사용 불가, CPU 사용.\n","경고: CPU 사용 시 임베딩 생성 속도가 매우 느립니다.\n"]}]},{"cell_type":"code","source":["# --- 데이터 경로 설정 ---\n","metadata_path = os.path.join(base_dir, '1_preprocessed', 'final_dataset', 'antibody_metadata_abnumber.parquet')\n","fasta_path = os.path.join(base_dir, '1_preprocessed', 'final_dataset', 'sequences', 'final_antibody_seqs_abnumber.fasta')\n","\n","# --- 메타데이터 로드 ---\n","print(f\"메타데이터 로딩 중: {metadata_path}\")\n","try:\n","    metadata_df = pd.read_parquet(metadata_path)\n","    print(f\"메타데이터 로드 완료: {len(metadata_df)} 항목\")\n","    # 필수 컬럼 확인\n","    required_cols = ['entry_id', 'vh_sequence', 'vl_sequence', 'vh_cdr3']\n","    if not all(col in metadata_df.columns for col in required_cols):\n","        missing_cols = [col for col in required_cols if col not in metadata_df.columns]\n","        print(f\"오류: 메타데이터에 필수 컬럼이 없습니다 - {missing_cols}\")\n","        # 필요한 조치 수행 (예: 스크립트 중단)\n","        raise ValueError(\"필수 메타데이터 컬럼 누락\")\n","except FileNotFoundError:\n","    print(f\"오류: 메타데이터 파일을 찾을 수 없습니다 - {metadata_path}\")\n","    # 필요한 조치 수행\n","    raise\n","except Exception as e:\n","    print(f\"메타데이터 로드 중 오류 발생: {e}\")\n","    raise\n","\n","# --- 서열 데이터 준비 ---\n","# 메타데이터에 서열 정보가 있으므로, 이를 사용\n","vh_sequences = metadata_df['vh_sequence'].tolist()\n","vl_sequences = metadata_df['vl_sequence'].tolist()\n","print(f\"VH/VL 서열 리스트 준비 완료: 각 {len(vh_sequences)} 개\")\n","\n","# FASTA 파일 로드는 검증용으로 사용 가능 (선택 사항)\n","# sequences = {}\n","# try:\n","#     for record in SeqIO.parse(fasta_path, \"fasta\"):\n","#         entry_id, chain_type = record.id.rsplit('_', 1)\n","#         if entry_id not in sequences:\n","#             sequences[entry_id] = {}\n","#         sequences[entry_id][chain_type] = str(record.seq)\n","#     print(f\"FASTA 파일 로드 완료 (검증용): {len(sequences)} 항목\")\n","# except FileNotFoundError:\n","#     print(f\"경고: FASTA 파일을 찾을 수 없습니다 - {fasta_path}\")\n","# except Exception as e:\n","#     print(f\"FASTA 파일 로드 중 오류 발생: {e}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XFJAYn8h9CpF","executionInfo":{"status":"ok","timestamp":1745893669134,"user_tz":-540,"elapsed":81,"user":{"displayName":"구글개정","userId":"15305168374719957285"}},"outputId":"699450ae-8491-4e91-b6f0-c61ff0f27164","collapsed":true},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["메타데이터 로딩 중: /content/drive/MyDrive/Antibody_AI_Data_Stage1_AbNumber/1_preprocessed/final_dataset/antibody_metadata_abnumber.parquet\n","메타데이터 로드 완료: 10594 항목\n","VH/VL 서열 리스트 준비 완료: 각 10594 개\n"]}]},{"cell_type":"code","source":["# --- 모델 선택 ---\n","# 옵션 1: 650M 모델 (Colab T4 GPU에서 실행 가능성 높음)\n","# model_name = \"facebook/esm2_t33_650M_UR50D\"\n","# batch_size_auto = 16 # T4 GPU 기준 추천 배치 크기 (메모리 부족 시 8로 줄임)\n","\n","# 옵션 2: 3B 모델 (Colab T4에서 메모리 부족 가능성 매우 높음, A100 등 고사양 GPU 필요)\n","model_name = \"facebook/esm2_t36_3B_UR50D\"\n","batch_size_auto = 4 # 3B 모델 + T4 GPU 사용 시 매우 작은 배치 크기 필요 (그래도 OOM 가능성 있음)\n","\n","# 옵션 3: 항체 특화 모델 (항체 특화 작업에 유리할 수 있음)\n","# model_name = \"ación/AntiBERTy\" # 정확한 모델 이름을 Hugging Face Hub에서 확인 필요\n","\n","print(f\"사용할 모델: {model_name}\")\n","print(f\"자동 설정 배치 크기: {batch_size_auto} (GPU 메모리 따라 조절 필요)\")\n","\n","# --- 모델 및 토크나이저 로드 ---\n","print(\"모델 및 토크나이저 로딩 중...\")\n","try:\n","    tokenizer = AutoTokenizer.from_pretrained(model_name)\n","    # allow_remote_code=True 는 신뢰할 수 있는 소스에서만 사용\n","    model = AutoModel.from_pretrained(model_name, trust_remote_code=True) # 일부 모델은 이 옵션 필요할 수 있음\n","    model.to(device)\n","    model.eval() # 평가 모드 설정\n","    print(\"모델 및 토크나이저 로드 완료.\")\n","except Exception as e:\n","    print(f\"모델 로딩 중 오류 발생: {e}\")\n","    # GPU 메모리 부족(OOM) 오류 발생 시 모델 크기나 배치 크기 재고려 필요\n","    raise\n","\n","# --- 개선된 임베딩 생성 함수 ---\n","def get_embeddings(sequence_list, batch_size=8, model=model, tokenizer=tokenizer, device=device, max_len=1024, progress_interval=10):\n","    \"\"\"\n","    주어진 서열 리스트로부터 pLM 임베딩을 생성합니다. (평균 풀링 방식, 패딩 제외)\n","\n","    Args:\n","        sequence_list (list): 아미노산 서열 문자열 리스트.\n","        batch_size (int): 한 번에 처리할 서열 수. GPU 메모리에 따라 조절.\n","        model: 사전 학습된 pLM 모델 객체.\n","        tokenizer: 해당 모델의 토크나이저 객체.\n","        device: 사용할 디바이스 ('cuda' 또는 'cpu').\n","        max_len (int): 토크나이저의 최대 입력 길이.\n","        progress_interval (int): 로그 출력 빈도 (배치 단위).\n","\n","    Returns:\n","        numpy.ndarray: 각 서열에 대한 임베딩 벡터 배열 (N x embedding_dim).\n","    \"\"\"\n","    all_embeddings = []\n","    num_sequences = len(sequence_list)\n","    num_batches = (num_sequences + batch_size - 1) // batch_size\n","    start_time_total = time.time()\n","    print(f\"총 서열 수: {num_sequences}, 배치 크기: {batch_size}, 총 배치 수: {num_batches}\")\n","\n","    # 모델을 평가 모드로 설정\n","    model.eval()\n","\n","    for i in range(num_batches):\n","        start_time_batch = time.time()\n","        # 배치 범위 계산 (리스트 인덱스 초과 방지)\n","        start_idx = i * batch_size\n","        end_idx = min((i + 1) * batch_size, num_sequences)\n","        batch_sequences = sequence_list[start_idx:end_idx]\n","\n","        if not batch_sequences: # 혹시 모를 빈 배치 처리\n","            continue\n","\n","        # 토크나이징 (패딩 및 트렁케이션 포함, PyTorch 텐서로 반환)\n","        try:\n","            inputs = tokenizer(\n","                batch_sequences,\n","                return_tensors=\"pt\",\n","                padding=\"max_length\", # max_length까지 패딩\n","                truncation=True,      # max_length 초과 시 잘라냄\n","                max_length=max_len    # 최대 길이 설정 (ESM 권장: 1024)\n","            ).to(device)\n","        except Exception as e:\n","            print(f\"오류: 배치 {i+1} 토크나이징 중 오류 발생: {e}\")\n","            print(f\"오류 발생 서열 (일부): {batch_sequences[:2]}\")\n","            # 오류 발생 시 빈 리스트나 None 반환 등 처리 필요\n","            return None # 또는 빈 배열 np.array([])\n","\n","        # 그래디언트 계산 비활성화 (메모리 절약 및 속도 향상)\n","        with torch.no_grad():\n","            try:\n","                # 모델 실행\n","                outputs = model(**inputs)\n","\n","                # 마지막 은닉 상태 (batch_size, sequence_length, hidden_size)\n","                last_hidden = outputs.last_hidden_state\n","\n","                # Attention mask (패딩 토큰은 0, 실제 토큰은 1)\n","                attention_mask = inputs['attention_mask']\n","\n","                # 패딩 토큰 제외하고 실제 토큰의 임베딩만 평균 계산\n","                # 1. 마스크 확장: (batch, seq_len) -> (batch, seq_len, hidden_size)\n","                input_mask_expanded = attention_mask.unsqueeze(-1).expand(last_hidden.size()).float()\n","                # 2. 실제 토큰 임베딩 합계 계산 (마스크된 부분은 0이 됨)\n","                sum_embeddings = torch.sum(last_hidden * input_mask_expanded, 1)\n","                # 3. 실제 토큰 수 계산 (0으로 나누는 것 방지)\n","                sum_mask = torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n","                # 4. 평균 임베딩 계산\n","                mean_embeddings = sum_embeddings / sum_mask\n","\n","                # 결과를 CPU로 이동하고 NumPy 배열로 변환하여 리스트에 추가\n","                all_embeddings.extend(mean_embeddings.cpu().numpy())\n","\n","            except RuntimeError as e:\n","                if \"out of memory\" in str(e):\n","                    print(f\"오류: 배치 {i+1} 처리 중 GPU 메모리 부족(OOM) 발생!\")\n","                    print(\"배치 크기를 줄여서 다시 시도해보세요.\")\n","                    # OOM 발생 시 None 반환하여 상위에서 처리하도록 함\n","                    return None\n","                else:\n","                    print(f\"오류: 배치 {i+1} 모델 실행 중 런타임 오류 발생: {e}\")\n","                    return None # 또는 빈 배열\n","            except Exception as e:\n","                 print(f\"오류: 배치 {i+1} 처리 중 예외 발생: {e}\")\n","                 return None # 또는 빈 배열\n","\n","        end_time_batch = time.time()\n","        # 지정된 간격마다 진행 상황 출력\n","        if (i + 1) % progress_interval == 0 or (i + 1) == num_batches:\n","            print(f\"  배치 {i+1}/{num_batches} 처리 완료. (배치 당 소요 시간: {end_time_batch - start_time_batch:.2f} 초)\")\n","\n","    end_time_total = time.time()\n","    print(f\"총 임베딩 생성 시간: {end_time_total - start_time_total:.2f} 초\")\n","\n","    # 최종 결과를 NumPy 배열로 변환하여 반환\n","    return np.array(all_embeddings)"],"metadata":{"id":"_cV1MRyp_5BH","colab":{"base_uri":"https://localhost:8080/","height":257,"referenced_widgets":["f71e2bcce13641a48f975b1bb2c04f05","8b38e72369a74fbe80c8f31ef417c992","a54ba924dad94a6ebd3f790bef8e44d1","1865fbc3507c4cd68e9b601f0aeb4fe0","d1bdf78d96714f2a92a4eccf7992b152","791e25b12a0d42eba11f66bb54c562ab","cd2df12d2d884841b814a25804a75813","62a0d23dedd74182986577f78725a964","701b3720db3d4c5fb88a7c5b481671f1","c417519e99764b23970953e97b4a9116","4f0b13da19c0427da5c93e4e4b0c252b"]},"executionInfo":{"status":"ok","timestamp":1745893680833,"user_tz":-540,"elapsed":11697,"user":{"displayName":"구글개정","userId":"15305168374719957285"}},"outputId":"56a583bc-1593-4aa4-ba61-7b764b538fd9"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["사용할 모델: facebook/esm2_t36_3B_UR50D\n","자동 설정 배치 크기: 4 (GPU 메모리 따라 조절 필요)\n","모델 및 토크나이저 로딩 중...\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f71e2bcce13641a48f975b1bb2c04f05"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of EsmModel were not initialized from the model checkpoint at facebook/esm2_t36_3B_UR50D and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["모델 및 토크나이저 로드 완료.\n"]}]},{"cell_type":"code","source":["# --- 임베딩 생성 실행 ---\n","# batch_size는 앞에서 설정한 batch_size_auto 사용 또는 직접 지정\n","# Colab T4 + 3B 모델 사용 시 매우 작은 값(예: 2, 4) 필요, OOM 발생 시 더 줄여야 함\n","effective_batch_size = batch_size_auto # 또는 4, 8 등 직접 지정\n","\n","print(\"\\n--- VH 서열 임베딩 생성 시작 ---\")\n","vh_embeddings = get_embeddings(vh_sequences, batch_size=effective_batch_size)\n","\n","# OOM 등으로 인해 None 반환 시 처리\n","if vh_embeddings is None:\n","    print(\"오류: VH 임베딩 생성 실패. 배치 크기 또는 모델을 확인하세요.\")\n","    # 필요시 여기서 중단\n","else:\n","    print(\"\\n--- VL 서열 임베딩 생성 시작 ---\")\n","    vl_embeddings = get_embeddings(vl_sequences, batch_size=effective_batch_size)\n","\n","    if vl_embeddings is None:\n","         print(\"오류: VL 임베딩 생성 실패. 배치 크기 또는 모델을 확인하세요.\")\n","    else:\n","        # --- 결과 저장 ---\n","        # 모델 이름과 크기를 파일명에 포함하여 구분 용이하게 함\n","        model_name_safe = model_name.split('/')[-1].replace('-', '_') # 파일명으로 사용 가능하게 변환\n","        vh_output_filename = f'vh_embeddings_{model_name_safe}.npy'\n","        vl_output_filename = f'vl_embeddings_{model_name_safe}.npy'\n","        vh_output_path = os.path.join(feature_dir, vh_output_filename)\n","        vl_output_path = os.path.join(feature_dir, vl_output_filename)\n","\n","        try:\n","            print(f\"\\nVH 임베딩 저장 중: {vh_output_path}\")\n","            np.save(vh_output_path, vh_embeddings)\n","            print(f\"VL 임베딩 저장 중: {vl_output_path}\")\n","            np.save(vl_output_path, vl_embeddings)\n","\n","            print(f\"\\n임베딩 저장 완료:\")\n","            print(f\"VH 임베딩 shape: {vh_embeddings.shape}\")\n","            print(f\"VL 임베딩 shape: {vl_embeddings.shape}\")\n","\n","            # 임베딩 경로를 메타데이터에 추가 (선택 사항)\n","            # metadata_df['vh_embedding_path'] = vh_output_path\n","            # metadata_df['vl_embedding_path'] = vl_output_path\n","            # metadata_output_path = os.path.join(feature_dir, 'metadata_with_embedding_paths.parquet')\n","            # metadata_df.to_parquet(metadata_output_path)\n","            # print(f\"임베딩 경로 포함된 메타데이터 저장: {metadata_output_path}\")\n","\n","        except Exception as e:\n","            print(f\"오류: 임베딩 저장 중 오류 발생: {e}\")"],"metadata":{"id":"ywIqgjSq_5jd","colab":{"base_uri":"https://localhost:8080/","height":460},"executionInfo":{"status":"error","timestamp":1745898545619,"user_tz":-540,"elapsed":4864769,"user":{"displayName":"구글개정","userId":"15305168374719957285"}},"outputId":"54fcbe7c-616c-49a1-81fe-24a1b550e69d"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","--- VH 서열 임베딩 생성 시작 ---\n","총 서열 수: 10594, 배치 크기: 4, 총 배치 수: 2649\n","  배치 10/2649 처리 완료. (배치 당 소요 시간: 138.10 초)\n","  배치 20/2649 처리 완료. (배치 당 소요 시간: 176.74 초)\n","  배치 30/2649 처리 완료. (배치 당 소요 시간: 182.11 초)\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-6-0a1cb2e9be5f>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n--- VH 서열 임베딩 생성 시작 ---\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mvh_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvh_sequences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meffective_batch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# OOM 등으로 인해 None 반환 시 처리\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-5-7d85b7e46e29>\u001b[0m in \u001b[0;36mget_embeddings\u001b[0;34m(sequence_list, batch_size, model, tokenizer, device, max_len, progress_interval)\u001b[0m\n\u001b[1;32m     83\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m                 \u001b[0;31m# 모델 실행\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m                 \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m                 \u001b[0;31m# 마지막 은닉 상태 (batch_size, sequence_length, hidden_size)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1749\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1750\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1751\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1752\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1753\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1760\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1761\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1762\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1763\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1764\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/esm/modeling_esm.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    907\u001b[0m             \u001b[0mpast_key_values_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpast_key_values_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    908\u001b[0m         )\n\u001b[0;32m--> 909\u001b[0;31m         encoder_outputs = self.encoder(\n\u001b[0m\u001b[1;32m    910\u001b[0m             \u001b[0membedding_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    911\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextended_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1749\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1750\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1751\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1752\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1753\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1760\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1761\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1762\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1763\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1764\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/esm/modeling_esm.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    610\u001b[0m                 )\n\u001b[1;32m    611\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 612\u001b[0;31m                 layer_outputs = layer_module(\n\u001b[0m\u001b[1;32m    613\u001b[0m                     \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    614\u001b[0m                     \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1749\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1750\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1751\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1752\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1753\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1760\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1761\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1762\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1763\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1764\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/esm/modeling_esm.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    542\u001b[0m             \u001b[0mpresent_key_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpresent_key_value\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mcross_attn_present_key_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 544\u001b[0;31m         \u001b[0mlayer_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeed_forward_chunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    545\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlayer_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/esm/modeling_esm.py\u001b[0m in \u001b[0;36mfeed_forward_chunk\u001b[0;34m(self, attention_output)\u001b[0m\n\u001b[1;32m    554\u001b[0m         \u001b[0mattention_output_ln\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLayerNorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    555\u001b[0m         \u001b[0mintermediate_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintermediate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention_output_ln\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 556\u001b[0;31m         \u001b[0mlayer_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mintermediate_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    557\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlayer_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    558\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1749\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1750\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1751\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1752\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1753\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1760\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1761\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1762\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1763\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1764\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/esm/modeling_esm.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, input_tensor)\u001b[0m\n\u001b[1;32m    466\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    467\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 468\u001b[0;31m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    469\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    470\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhidden_states\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0minput_tensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1749\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1750\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1751\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1752\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1753\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1760\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1761\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1762\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1763\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1764\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":["# --- CD-HIT 설치 (Colab 환경) ---\n","# 필요한 빌드 도구 설치\n","print(\"CD-HIT 설치 시작 (빌드 도구 설치 및 컴파일)...\")\n","!sudo apt-get update -qq > /dev/null\n","!sudo apt-get install -y build-essential -qq > /dev/null\n","\n","# CD-HIT 소스 다운로드 및 압축 해제\n","!wget https://github.com/weizhongli/cdhit/releases/download/V4.8.1/cd-hit-v4.8.1-2019-0228.tar.gz -q\n","!tar -xzf cd-hit-v4.8.1-2019-0228.tar.gz\n","\n","# CD-HIT 컴파일 (오류 발생 시 로그 확인 필요)\n","print(\"CD-HIT 컴파일 중...\")\n","compile_log = !cd cd-hit-v4.8.1-2019-0228 && make\n","if \"error\" in \"\".join(compile_log).lower():\n","     print(\"오류: CD-HIT 컴파일 실패!\")\n","     print(\"\\n\".join(compile_log))\n","else:\n","     print(\"CD-HIT 컴파일 성공.\")\n","     # 실행 파일 경로 설정\n","     cd_hit_executable = '/content/cd-hit-v4.8.1-2019-0228/cd-hit'\n","     # 실행 권한 부여 (필요한 경우)\n","     !chmod +x {cd_hit_executable}\n","     # 버전 확인\n","     !{cd_hit_executable} -h | head -n 5\n","\n","# 컴파일 실패 시 대안: 사전 컴파일된 바이너리 사용 시도 (제공 여부 확인 필요)\n","# 또는 웹 서버 이용 고려"],"metadata":{"id":"jkinz62m_xsf","executionInfo":{"status":"aborted","timestamp":1745898545621,"user_tz":-540,"elapsed":5,"user":{"displayName":"구글개정","userId":"15305168374719957285"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# --- CD-HIT 실행 준비 ---\n","\n","# 1. 클러스터링 기준 서열 선택 및 FASTA 파일 생성\n","#    기준: VH CDR3 (가장 다양성이 높음). 다른 기준(예: VH 전체) 사용 가능.\n","#    이전 셀에서 metadata_df가 로드되었다고 가정.\n","print(\"\\n--- CD-HIT 입력 FASTA 파일 생성 ---\")\n","cdr3_sequences_for_cdhit = []\n","if 'vh_cdr3' in metadata_df.columns:\n","    for index, row in metadata_df.iterrows():\n","        entry_id = row['entry_id'] # 각 서열의 고유 ID\n","        cdr3_seq = str(row['vh_cdr3']) if pd.notna(row['vh_cdr3']) else \"\"\n","        if cdr3_seq and len(cdr3_seq) > 0: # 유효한 CDR3 서열만 포함\n","            # SeqRecord 생성 (FASTA 헤더 >entry_id)\n","            record = SeqRecord(Seq(cdr3_seq), id=str(entry_id), description=\"\") # ID는 문자열이어야 함\n","            cdr3_sequences_for_cdhit.append(record)\n","        else:\n","            print(f\"경고: Entry ID {entry_id}의 VH CDR3 서열이 유효하지 않아 제외됩니다.\")\n","else:\n","    print(\"오류: 'vh_cdr3' 컬럼이 메타데이터에 없습니다.\")\n","    # 오류 처리 또는 중단 필요\n","    raise ValueError(\"'vh_cdr3' 컬럼 누락\")\n","\n","# FASTA 파일 저장 경로 (Colab 내 임시 저장 또는 Drive)\n","# 작업 편의상 /content/ 에 저장 후 필요시 Drive로 복사\n","input_fasta_filename = 'vh_cdr3_sequences_for_cdhit.fasta'\n","input_fasta_path = f'/content/{input_fasta_filename}' # Colab 임시 경로\n","\n","try:\n","    with open(input_fasta_path, \"w\") as output_handle:\n","        SeqIO.write(cdr3_sequences_for_cdhit, output_handle, \"fasta\")\n","    print(f\"VH CDR3 서열 ({len(cdr3_sequences_for_cdhit)}개) FASTA 파일 저장 완료: {input_fasta_path}\")\n","except Exception as e:\n","    print(f\"FASTA 파일 저장 중 오류 발생: {e}\")\n","    raise\n","\n","# 2. 출력 파일 Prefix 설정 (결과 파일들이 저장될 기본 이름)\n","#    결과 파일 저장 위치: feature_dir 또는 split_dir 사용\n","output_prefix_base = 'vh_cdr3_clusters_90' # 예시: 90% 유사도 기준 클러스터\n","output_prefix = os.path.join(feature_dir, output_prefix_base) # 결과 파일 저장 경로\n","# 주의: Colab의 ! 명령어는 Google Drive 경로에 직접 쓰는 것이 불안정할 수 있음.\n","# /content/ 에 생성 후 Drive로 복사하는 것을 권장.\n","colab_output_prefix = f'/content/{output_prefix_base}'\n","\n","# 3. CD-HIT 실행 옵션 설정\n","identity_threshold = 0.9 # 서열 유사도 임계값 (0.9 = 90%). 모델 검증 엄격성을 위해 0.8 등 더 낮출 수 있음.\n","word_size = 5 # n-gram 워드 크기. 짧은 CDR 서열에는 4 또는 5가 적합. (CD-HIT 문서 참조)\n","# 참고: CDR3 평균 길이가 약 16이므로, word_size=5는 적절한 시작점.\n","\n","# 4. CD-HIT 실행 (Colab ! 명령어 사용)\n","#    실행 파일 경로: 이전 셀에서 설정한 cd_hit_executable 사용\n","command = f\"{cd_hit_executable} -i {input_fasta_path} -o {colab_output_prefix} -c {identity_threshold} -n {word_size} -M 0 -T 0\"\n","# -M 0: 메모리 제한 없음 (Colab 환경 고려)\n","# -T 0: 사용 가능한 모든 스레드 사용\n","\n","print(f\"\\n--- CD-HIT 실행 (Colab) ---\")\n","print(f\"명령어: {command}\")\n","\n","try:\n","    # ! 명령어 실행 및 결과 저장\n","    cdhit_output = !{command}\n","    # 실행 결과 출력 (디버깅용)\n","    print(\"\\n--- CD-HIT 실행 로그 ---\")\n","    for line in cdhit_output:\n","        print(line)\n","    print(\"---------------------\")\n","\n","    # 출력 파일 존재 확인\n","    cluster_file_path_colab = f\"{colab_output_prefix}.clstr\"\n","    if os.path.exists(cluster_file_path_colab):\n","        print(f\"CD-HIT 실행 성공. 클러스터 파일 생성됨: {cluster_file_path_colab}\")\n","        # 생성된 파일을 Google Drive로 복사 (선택 사항)\n","        cluster_file_path_drive = f\"{output_prefix}.clstr\"\n","        !cp {cluster_file_path_colab} \"{cluster_file_path_drive}\" # 경로에 공백 있을 수 있으므로 따옴표 사용\n","        print(f\"클러스터 파일을 Drive로 복사 완료: {cluster_file_path_drive}\")\n","    else:\n","        print(f\"오류: CD-HIT 실행은 되었으나 클러스터 파일({cluster_file_path_colab})이 생성되지 않았습니다.\")\n","        print(\"CD-HIT 로그를 확인하여 원인을 파악하세요.\")\n","        # 오류 처리\n","\n","except Exception as e:\n","    print(f\"CD-HIT 실행 중 예외 발생: {e}\")\n","    # 오류 처리"],"metadata":{"id":"hZqu4zxuAQ5_","executionInfo":{"status":"aborted","timestamp":1745898545622,"user_tz":-540,"elapsed":5,"user":{"displayName":"구글개정","userId":"15305168374719957285"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def parse_cdhit_clstr(clstr_file_path):\n","    \"\"\"\n","    CD-HIT의 .clstr 파일을 파싱하여 각 서열 ID와 클러스터 ID를 매핑하는 딕셔너리를 반환합니다.\n","\n","    Args:\n","        clstr_file_path (str): .clstr 파일의 경로.\n","\n","    Returns:\n","        dict: {entry_id: cluster_id} 형태의 딕셔너리.\n","               파싱 실패 시 None 반환.\n","    \"\"\"\n","    clusters = {}\n","    current_cluster_id = -1\n","    try:\n","        with open(clstr_file_path, 'r') as f:\n","            for line in f:\n","                if line.startswith('>Cluster'):\n","                    # 새 클러스터 시작, 클러스터 ID 추출 (예: >Cluster 0 -> 0)\n","                    try:\n","                        current_cluster_id = int(line.strip().split()[-1])\n","                    except (IndexError, ValueError):\n","                         print(f\"경고: 클러스터 ID 파싱 오류 - {line.strip()}\")\n","                         current_cluster_id = -1 # 오류 발생 시 유효하지 않은 ID로 설정\n","                elif line.strip():\n","                    # 클러스터 멤버 라인\n","                    # 예: 0   117aa, >SAbDab_8h9h_VH... *\n","                    match = re.search(r'>(\\S+)\\.\\.\\.', line) # FASTA 헤더 ID (entry_id) 추출\n","                    if match and current_cluster_id != -1:\n","                        entry_id = match.group(1)\n","                        clusters[entry_id] = current_cluster_id\n","                    else:\n","                        # FASTA 헤더에서 ID 추출 실패 시 경고\n","                         print(f\"경고: 서열 ID 파싱 오류 또는 유효하지 않은 클러스터 ID - {line.strip()}\")\n","        print(f\"클러스터 파일 파싱 완료: 총 {len(set(clusters.values()))}개 클러스터, {len(clusters)}개 서열 매핑됨.\")\n","        return clusters\n","    except FileNotFoundError:\n","        print(f\"오류: 클러스터 파일을 찾을 수 없습니다 - {clstr_file_path}\")\n","        return None\n","    except Exception as e:\n","        print(f\"클러스터 파일 파싱 중 오류 발생: {e}\")\n","        return None"],"metadata":{"id":"q_IE_jUsTd3W","executionInfo":{"status":"aborted","timestamp":1745898545623,"user_tz":-540,"elapsed":5,"user":{"displayName":"구글개정","userId":"15305168374719957285"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# --- 클러스터 파일 파싱 실행 ---\n","# 이전 셀에서 Drive로 복사된 클러스터 파일 경로 사용\n","cluster_file_path = f\"{output_prefix}.clstr\" # Drive 내 클러스터 파일 경로\n","print(f\"\\n--- 클러스터 파일 파싱 시작: {cluster_file_path} ---\")\n","entry_to_cluster = parse_cdhit_clstr(cluster_file_path)\n","\n","if entry_to_cluster is None:\n","    print(\"오류: 클러스터 정보 파싱 실패. 데이터 분할을 진행할 수 없습니다.\")\n","    # 오류 처리 또는 중단\n","    raise ValueError(\"클러스터 파싱 실패\")\n","else:\n","    # --- 그룹 정보 생성 ---\n","    # 메타데이터의 entry_id를 기준으로 클러스터 ID(그룹) 할당\n","    # CD-HIT에 포함되지 않은 서열(예: CDR3 없거나 짧음) 처리 필요\n","    groups = metadata_df['entry_id'].map(entry_to_cluster).fillna(-1).astype(int) # 클러스터 없으면 -1 할당\n","    metadata_df['cluster_id'] = groups # 메타데이터에 클러스터 ID 추가\n","\n","    # 클러스터링되지 않은 데이터 수 확인\n","    num_unclustered = (groups == -1).sum()\n","    if num_unclustered > 0:\n","        print(f\"경고: {num_unclustered}개의 서열이 클러스터링되지 않았습니다 (그룹 ID: -1). 이들은 별도로 처리될 수 있습니다.\")\n","\n","    # --- 데이터 분할 실행 (GroupShuffleSplit 사용) ---\n","    # 특성 데이터 로드 (이전에 생성된 임베딩 파일 경로 확인)\n","    try:\n","        model_name_safe = model_name.split('/')[-1].replace('-', '_')\n","        vh_embeddings_path = os.path.join(feature_dir, f'vh_embeddings_{model_name_safe}.npy')\n","        vl_embeddings_path = os.path.join(feature_dir, f'vl_embeddings_{model_name_safe}.npy')\n","        vh_embeddings = np.load(vh_embeddings_path)\n","        vl_embeddings = np.load(vl_embeddings_path)\n","        print(f\"임베딩 데이터 로드 완료: {vh_embeddings_path}, {vl_embeddings_path}\")\n","    except FileNotFoundError:\n","        print(\"오류: 저장된 임베딩 파일을 찾을 수 없습니다. 이전 단계를 확인하세요.\")\n","        raise\n","    except Exception as e:\n","        print(f\"임베딩 로드 중 오류 발생: {e}\")\n","        raise\n","\n","    # 데이터 인덱스 준비 (클러스터링된 데이터만 사용하거나, -1 그룹 처리 방식 결정 필요)\n","    # 여기서는 모든 데이터를 사용하되, -1 그룹은 각자 다른 그룹처럼 취급될 수 있음\n","    indices = np.arange(len(metadata_df))\n","\n","    # 훈련/테스트 분할 (예: 80% 훈련, 20% 테스트)\n","    # n_splits=1: 한 번만 분할 수행\n","    # test_size=0.2: 테스트 세트 비율 20%\n","    # random_state: 재현성을 위한 시드 값\n","    gss_test = GroupShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n","    print(\"\\n--- 훈련/테스트 데이터 분할 (GroupShuffleSplit) ---\")\n","    train_val_idx, test_idx = next(gss_test.split(indices, groups=groups))\n","\n","    # 훈련 세트를 다시 훈련/검증으로 분할 (예: 훈련 데이터 중 약 10~15% 검증)\n","    # test_size 계산 시 전체 데이터가 아닌 train_val_idx 기준으로 비율 설정 필요\n","    validation_split_ratio = 0.125 # 예: 80% 중 12.5% -> 전체의 10%\n","    gss_val = GroupShuffleSplit(n_splits=1, test_size=validation_split_ratio, random_state=42)\n","    print(\"--- 훈련/검증 데이터 분할 (GroupShuffleSplit) ---\")\n","    train_idx, val_idx = next(gss_val.split(indices[train_val_idx], groups=groups[train_val_idx]))\n","\n","    # 원본 데이터프레임 기준의 최종 인덱스 계산\n","    original_train_idx = train_val_idx[train_idx]\n","    original_val_idx = train_val_idx[val_idx]\n","    original_test_idx = test_idx # gss_test에서 반환된 인덱스 사용\n","\n","    # --- 분할된 데이터 생성 ---\n","    # 임베딩 데이터 분할\n","    X_train_vh, X_val_vh, X_test_vh = vh_embeddings[original_train_idx], vh_embeddings[original_val_idx], vh_embeddings[original_test_idx]\n","    X_train_vl, X_val_vl, X_test_vl = vl_embeddings[original_train_idx], vl_embeddings[original_val_idx], vl_embeddings[original_test_idx]\n","\n","    # 메타데이터 분할\n","    metadata_train = metadata_df.iloc[original_train_idx].copy() # SettingWithCopyWarning 방지\n","    metadata_val = metadata_df.iloc[original_val_idx].copy()\n","    metadata_test = metadata_df.iloc[original_test_idx].copy()\n","\n","    print(\"\\n--- 데이터 분할 결과 ---\")\n","    print(f\"훈련 세트 크기: {len(metadata_train)}\")\n","    print(f\"검증 세트 크기: {len(metadata_val)}\")\n","    print(f\"테스트 세트 크기: {len(metadata_test)}\")\n","    print(f\"총합: {len(metadata_train) + len(metadata_val) + len(metadata_test)} (원본: {len(metadata_df)})\")\n","\n","    # 분할 비율 확인 (근사치)\n","    total_size = len(metadata_df)\n","    print(f\"분할 비율 (Train/Val/Test): {len(metadata_train)/total_size:.2f} / {len(metadata_val)/total_size:.2f} / {len(metadata_test)/total_size:.2f}\")\n","\n","    # --- 분할된 데이터 저장 ---\n","    print(f\"\\n--- 분할된 데이터 저장 시작 ({split_dir}) ---\")\n","    try:\n","        # 임베딩 저장\n","        np.save(os.path.join(split_dir, 'X_train_vh.npy'), X_train_vh)\n","        np.save(os.path.join(split_dir, 'X_val_vh.npy'), X_val_vh)\n","        np.save(os.path.join(split_dir, 'X_test_vh.npy'), X_test_vh)\n","        np.save(os.path.join(split_dir, 'X_train_vl.npy'), X_train_vl)\n","        np.save(os.path.join(split_dir, 'X_val_vl.npy'), X_val_vl)\n","        np.save(os.path.join(split_dir, 'X_test_vl.npy'), X_test_vl)\n","        print(\"임베딩 데이터 (Train/Val/Test) 저장 완료.\")\n","\n","        # 메타데이터 저장\n","        metadata_train.to_parquet(os.path.join(split_dir, 'metadata_train.parquet'))\n","        metadata_val.to_parquet(os.path.join(split_dir, 'metadata_val.parquet'))\n","        metadata_test.to_parquet(os.path.join(split_dir, 'metadata_test.parquet'))\n","        print(\"메타데이터 (Train/Val/Test) 저장 완료.\")\n","\n","    except Exception as e:\n","        print(f\"분할된 데이터 저장 중 오류 발생: {e}\")"],"metadata":{"id":"rPdNgnuHTeek","executionInfo":{"status":"aborted","timestamp":1745898545624,"user_tz":-540,"elapsed":6,"user":{"displayName":"구글개정","userId":"15305168374719957285"}}},"execution_count":null,"outputs":[]}]}